#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
A general MUSHRA (MUltiple Stimulus Hidden Reference and Anchor) configuration for evaluating overall quality
of a set of audio stimuli.
"""
# ---------------------------------------------------------------------------------------------
# TESTING VARIABLES
TEST_TYPE = 'mushra'
TEST_CONDITION_GROUP_ORDER_RANDOMIZED = True

# ---------------------------------------------------------------------------------------------
# FRONT-END VARIABLES
TEST_TIMEOUT_SEC = 60.
PREVIEW_HTML = """
    <p>This listening test aims to rate the quality of a set of signals in comparison to a reference signal.</p>

    <p>During the test, you will be asked to assess the quality of the audio. The test will have two main parts:
    1) a training phase and 2) an evaluation phase. During the training phase, you will have to listen to all the
    recordings and learn the range of quality that is possible. During the evaluation phase, you will have to rate
    the quality of eight test recordings compared to a reference sound.</p>

    <p>The expected total duration of the test is 5 minutes.</p>

    <p>However, if this is your first HIT in this group, there will also be additional surveys and hearing tests, which
    will increase the expected total duration of the first HIT is 8 minutes. Because this first HIT takes longer than
    the rest of the HITs in this group, you will be given a $0.30 bonus.</p>
    """

# ---------------------------------------------------------------------------------------------
# DEFAULT CONDITION AND TEST-SPECIFIC VARIABLES
#   (These will be configured for each condition and saved in the database)
test_title = 'Task: Rate the <quality>'

first_task_introduction_html = """
    <p>This listening test aims to rate the quality of a set of signals in comparison to a reference signal.</p>

    <p>During the training phase, you will have to listen to all the recordings and learn the range of quality
    that is possible. During the evaluation phase, you will have to rate the quality of eight test recordings
    compared to the perfect target sound. Lastly, at the end, there will be some additional questions which you will
    only have to fill out for the first HIT of the group you complete.</p>
    """

introduction_html = """
    <p>This listening test aims to rate the quality of a set of signals in comparison to a reference signal.</p>

    <p>During the training phase, you will have to listen to all the recordings and learn the range of quality
    that is possible. During the evaluation phase, you will have to rate the quality of eight test recordings
    compared to the perfect target sound.</p>
    """

training_instructions_html = """
    <p><quality_explanation></p>

    <p>Instructions:
    <ol>
    <li>If you have not done so already, set the volume of your headphones/speakers so that
    it's comfortable. You should be able to clearly hear differences between recordings
    (the volume shouldn't be changed later on).</li>
    <li>You must fully listen to all of the recordings before proceeding to the next
    section.</li>
    <li>Train yourself on the example recordings to learn what types of recordings we
    expect to receive a higher or lower than average rating according to the quality scale.</li>
    <li>Train yourself to notice the <quality> and learn the range of <quality>.</li>
    </ol>
    </p>
     """

evaluation_instructions_html = """
    <p><b>Rate the <quality> on a scale from 0 to 100</b>, where larger ratings indicate
    better quality. <quality_explanation></p>

    <p>You can listen to the recordings as many times as you want before deciding. Once you
    have rated all recordings, listen to them again to make sure that the ratings between
    pairs of recordings are consistent, i.e. if one recording has better quality than
    another, it should be rated higher.</p>
    """

references = (('Reference', 'The reference signal to which test signals are compared.'),)

num_audio_files = 10

# The quality scales
qualities = ['<b>overall quality</b> compared to the reference sound for each recording', ]

# Descriptions of the quality scales
quality_explanations = ['<b>Overall quality</b> refers to overall quality of a recording based on how similar it is'
                        ' to the reference sound. For example, if a recording is very similar to the the reference,'
                        ' it should be given a high rating. However, if a recording is very different from the '
                        'reference sound (e.g. because of degradation or additional sounds), it should be given a low'
                        ' rating.', ]

# ---------------------------------------------------------------------------------------------
# TRAINING EXAMPLES FOR PARTICIPANTS
# These are the reference examples for the training examples
# List entries must be dicts composed as {<reference_name>: <example_url>, ...}
reference_example_dicts = [{'Reference': '/audio/exp00_target.wav', }, ]

# These are the quality examples.
# List entries should be dicts composed as {<description>: <example_url>, ...}
quality_example_dicts = [{'Low': ['/audio/exp00_anchorArtif.wav',
                                  '/audio/exp00_anchorDistTarget.wav'],
                          'High': ['/audio/exp00_target.wav', ]}, ]

TESTS = []
for quality, quality_explanation, reference_example_dict, quality_example_dict in zip(qualities,
                                                                                      quality_explanations,
                                                                                      reference_example_dicts,
                                                                                      quality_example_dicts, ):
    test_cfg_vars = {}
    test_cfg_vars['references'] = references

    test_cfg_vars['reference_example_dict'] = reference_example_dict
    test_cfg_vars['quality_example_dict'] = quality_example_dict

    test_cfg_vars['test_title'] = test_title
    test_cfg_vars['test_title'] = test_cfg_vars['test_title'].replace('<quality>', quality)

    test_cfg_vars['introduction_html'] = introduction_html
    test_cfg_vars['introduction_html'] = test_cfg_vars['introduction_html'].replace('<quality>', quality)
    test_cfg_vars['introduction_html'] = test_cfg_vars['introduction_html'].replace('<quality_explanation>', quality_explanation)

    test_cfg_vars['first_task_introduction_html'] = first_task_introduction_html
    test_cfg_vars['first_task_introduction_html'] = test_cfg_vars['first_task_introduction_html'].replace('<quality>', quality)
    test_cfg_vars['first_task_introduction_html'] = test_cfg_vars['first_task_introduction_html'].replace('<quality_explanation>', quality_explanation)

    test_cfg_vars['training_instructions_html'] = training_instructions_html
    test_cfg_vars['training_instructions_html'] = test_cfg_vars['training_instructions_html'].replace('<quality>', quality)
    test_cfg_vars['training_instructions_html'] = test_cfg_vars['training_instructions_html'].replace('<quality_explanation>', quality_explanation)

    test_cfg_vars['evaluation_instructions_html'] = evaluation_instructions_html
    test_cfg_vars['evaluation_instructions_html'] = test_cfg_vars['evaluation_instructions_html'].replace('<quality>', quality)
    test_cfg_vars['evaluation_instructions_html'] = test_cfg_vars['evaluation_instructions_html'].replace('<quality_explanation>', quality_explanation)

    test = {'test_config_variables': test_cfg_vars,
            'condition_groups': []}

    for i in range(1, num_audio_files + 1):
        # THE AUDIO STIMULUS FILES
        group_data = {'reference_files': [['Reference', 'exp%02d_target.wav' % i],],
                      'stimulus_files': [['S1', 'exp%02d_target.wav' % i],
                                         ['S2', 'exp%02d_anchorArtif.wav' % i],
                                         ['S3', 'exp%02d_anchorDistTarget.wav' % i],
                                         ['S4', 'exp%02d_test5.wav' % i],
                                         ['S5', 'exp%02d_test6.wav' % i],
                                         ['S6', 'exp%02d_test7.wav' % i],
                                         ['S7', 'exp%02d_test8.wav' % i]]}
        condition_data = {'reference_keys': ['Reference', ],
                          'stimulus_keys': ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', ],
                          'evaluation_instructions_html': None}
        group_data['conditions'] = [condition_data, ]
        test['condition_groups'].append(group_data)
    TESTS.append(test)

MTURK_TITLE='Source separation listening task. Listen to audio recordings and rate them on various scales of quality.'
